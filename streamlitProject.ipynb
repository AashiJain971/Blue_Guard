{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e78d530-2e74-4f03-a2f2-71ba2dbc3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sqlite3, pathlib, os, io, base64, zipfile, re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup ---\n",
    "BASE_DIR = pathlib.Path().absolute()\n",
    "DB_PATH = str(BASE_DIR / \"access_logs.db\")\n",
    "ASSETS = BASE_DIR / \"assets\"\n",
    "STATIC_DIR = BASE_DIR / \"static\"\n",
    "REPORTS_DIR = BASE_DIR / \"reports\"\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "DARK_BG = \"#0e1117\"\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"axes.facecolor\"] = DARK_BG\n",
    "plt.rcParams[\"figure.facecolor\"] = DARK_BG\n",
    "\n",
    "def _run_sql(query: str, **kw) -> pd.DataFrame:\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        return pd.read_sql_query(query, conn, **kw)\n",
    "\n",
    "def get_csv_download_link(df, filename):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode()).decode()\n",
    "    return f'<a href=\"data:file/csv;base64,{b64}\" download=\"{filename}\">Download CSV</a>'\n",
    "\n",
    "\n",
    "# --- Helper functions for bounds ---\n",
    "def _bounds(table: str, column: str):\n",
    "    q = f\"SELECT MIN({column}) AS min_t, MAX({column}) AS max_t FROM {table}\"\n",
    "    df = _run_sql(q)\n",
    "    if df.empty or df.isnull().any(axis=None):\n",
    "        return None, None\n",
    "    return pd.to_datetime(df.min_t[0]), pd.to_datetime(df.max_t[0])\n",
    "\n",
    "LOG_MIN, LOG_MAX = _bounds(\"logs\", \"time\")\n",
    "SUS_MIN, SUS_MAX = _bounds(\"ip_suspicious\", \"time\")\n",
    "BLK_MIN, BLK_MAX = _bounds(\"blocked_log\", \"backend_blocked_at\")\n",
    "ADV_MIN, ADV_MAX = _bounds(\"advanced_logs\", \"first_time_of_access\")\n",
    "DDOS_MIN, DDOS_MAX = _bounds(\"ddos_multiple_ip\", \"window_start\")\n",
    "\n",
    "# Global span across all tables\n",
    "GLOBAL_MIN = min(ts for ts in (LOG_MIN, SUS_MIN, BLK_MIN, ADV_MIN, DDOS_MIN) if ts is not None)\n",
    "GLOBAL_MAX = max(ts for ts in (LOG_MAX, SUS_MAX, BLK_MAX, ADV_MAX, DDOS_MAX) if ts is not None)\n",
    "\n",
    "def get_bounds(col):\n",
    "    df = _run_sql(f\"SELECT MIN({col}) as min_t, MAX({col}) as max_t FROM logs\")\n",
    "    if df.empty or df.isnull().any(axis=None):\n",
    "        now = datetime.now().astimezone()\n",
    "        return now, now\n",
    "    return pd.to_datetime(df.iloc[0][\"min_t\"]), pd.to_datetime(df.iloc[0][\"max_t\"])\n",
    "\n",
    "LOG_MIN, LOG_MAX = get_bounds(\"time\")\n",
    "ING_MIN, ING_MAX = get_bounds(\"ingest_ts\")\n",
    "\n",
    "# --- Sidebar: Logo and time spans only ---\n",
    "with st.sidebar:\n",
    "    st.image(str(ASSETS / \"BlueGuardLogo.jpg\"), use_container_width=True)\n",
    "    st.markdown(\"### Dataset Time Spans\")\n",
    "    st.write(f\"**Log time:** {LOG_MIN.date()} ‚Üí {LOG_MAX.date()}\")\n",
    "    st.write(f\"**Ingest time:** {ING_MIN.date()} ‚Üí {ING_MAX.date()}\")\n",
    "    st.markdown(\"---\")\n",
    "    st.caption(\"Blue‚ÄØGuard¬†SIEM¬†¬©‚ÄØ2025\")\n",
    "\n",
    "st.set_page_config(\"Blue-Guard SIEM\", \"üõ°Ô∏è\", layout=\"wide\")\n",
    "st.markdown(f\"\"\"\n",
    "<style>\n",
    "  .stApp{{background:{DARK_BG};color:#f0f2f6;}}\n",
    "  [data-testid=stSidebar]{{background:#1a1d24!important;border-right:1px solid #2a2e36;}}\n",
    "  .stMetric{{background:#1a1d24;border-radius:8px;padding:15px;border-left:4px solid #4ba3c7;}}\n",
    "  ::-webkit-scrollbar{{width:8px;}}::-webkit-scrollbar-track{{background:#1a1d24;}}\n",
    "  ::-webkit-scrollbar-thumb{{background:#4ba3c7;border-radius:4px;}}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "tabs = st.tabs([\n",
    "    \"Overview\", \"Traffic\", \"Threats\", \"Suspicious IPs\", \"Blocked IPs\", \"Geography\", \"Advanced\", \"Report\", \"System\"\n",
    "])\n",
    "\n",
    "all_figs = {}\n",
    "\n",
    "# --- Overview ---\n",
    "with tabs[0]:\n",
    "    st.title(\"üõ°Ô∏è Blue‚ÄëGuard SIEM ‚Äî Overview\")\n",
    "    st.markdown(\"#### Executive Summary\")\n",
    "    logs = _run_sql(\"SELECT COUNT(*) as logs FROM logs\").iloc[0,0]\n",
    "    uips = _run_sql(\"SELECT COUNT(DISTINCT ip) as uips FROM logs\").iloc[0,0]\n",
    "    blocked = _run_sql(\"SELECT COUNT(*) as blocked FROM blocked_log\").iloc[0,0]\n",
    "    sus = _run_sql(\"SELECT COUNT(DISTINCT suspiciousIp) as sus FROM ip_suspicious\").iloc[0,0]\n",
    "    st.markdown(f\"\"\"\n",
    "    - **Total log events:** {logs:,}\n",
    "    - **Unique IPs:** {uips:,}\n",
    "    - **Blocked IPs:** {blocked:,}\n",
    "    - **Suspicious IPs:** {sus:,}\n",
    "    \"\"\")\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    col1.metric(\"Logs\", f\"{logs:,}\")\n",
    "    col2.metric(\"Unique IPs\", f\"{uips:,}\", delta=f\"{sus/uips:.1%} suspicious\" if uips else None)\n",
    "    col3.metric(\"Blocked IPs\", f\"{blocked:,}\")\n",
    "    col4.metric(\"Suspicious IPs\", f\"{sus:,}\")\n",
    "    st.divider()\n",
    "    st.subheader(\"üî• Suspicious IPs per Day\")\n",
    "    days = st.slider(\"Days to show\", 7, 60, 15, key=\"sus_days\")\n",
    "    df = _run_sql(f\"\"\"\n",
    "        SELECT DATE(time) AS day, COUNT(*) AS cnt\n",
    "        FROM   ip_suspicious\n",
    "        WHERE  DATE(time) >= DATE('now', '-{days-1} day')\n",
    "        GROUP  BY day\n",
    "        ORDER  BY day\n",
    "    \"\"\")\n",
    "    if not df.empty:\n",
    "        all_days = pd.date_range(end=pd.Timestamp.today().normalize(), periods=days, freq=\"D\")\n",
    "        df = (df.set_index(\"day\").reindex(all_days.strftime(\"%Y-%m-%d\"), fill_value=0)\n",
    "                .rename_axis(\"day\").reset_index())\n",
    "        fig, ax = plt.subplots(facecolor=DARK_BG)\n",
    "        palette = sns.color_palette(\"pastel\", len(df))\n",
    "        sns.barplot(data=df, x=\"day\", y=\"cnt\", palette=palette, ax=ax, edgecolor=\"black\", linewidth=.5)\n",
    "        for p, val in zip(ax.patches, df[\"cnt\"]):\n",
    "            ax.text(p.get_x() + p.get_width()/2, p.get_height() + max(df[\"cnt\"])*0.02, f\"{val:,}\", ha=\"center\", va=\"bottom\", fontsize=10, color=\"w\")\n",
    "        ax.set(title=\"Suspicious IPs per Day\", xlabel=\"Date\", ylabel=\"Count\")\n",
    "        plt.xticks(rotation=45, ha=\"right\", color=\"w\")\n",
    "        plt.yticks(color=\"w\")\n",
    "        ax.title.set_color(\"w\")\n",
    "        fig.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        all_figs[\"suspicious_trend.png\"] = fig\n",
    "    st.markdown(get_csv_download_link(df, \"suspicious_trend.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Traffic ---\n",
    "with tabs[1]:\n",
    "    st.title(\"üåê Traffic Patterns\")\n",
    "    min_day, max_day = _run_sql(\"SELECT MIN(DATE(time)), MAX(DATE(time)) FROM logs\").iloc[0]\n",
    "    date_range = st.date_input(\"Select date range\", value=(pd.to_datetime(min_day), pd.to_datetime(max_day)), key=\"traffic_date_range\")\n",
    "    start, end = date_range if isinstance(date_range, (list, tuple)) else (min_day, max_day)\n",
    "    st.subheader(\"Hourly/Weekly Heatmap\")\n",
    "    df = _run_sql(f\"\"\"\n",
    "        SELECT strftime('%w', time) wd, strftime('%H', time) hr, COUNT(*) cnt \n",
    "        FROM logs \n",
    "        WHERE DATE(time) BETWEEN '{start}' AND '{end}'\n",
    "        GROUP BY wd, hr\n",
    "    \"\"\")\n",
    "    if not df.empty:\n",
    "        df[\"wd\"] = df[\"wd\"].astype(int)\n",
    "        df[\"hr\"] = df[\"hr\"].astype(int)\n",
    "        pivot = df.pivot(index=\"wd\", columns=\"hr\", values=\"cnt\").fillna(0)\n",
    "        weekday_labels = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "        fig, ax = plt.subplots(figsize=(14, 5), facecolor=DARK_BG)\n",
    "        sns.heatmap(pivot, cmap=\"YlOrRd\", linewidths=0.5, xticklabels=range(24), yticklabels=weekday_labels, ax=ax, cbar_kws={'label': 'Hits'})\n",
    "        plt.title(\"Request Heatmap: Hourly Activity by Weekday\", color=\"w\", pad=20)\n",
    "        plt.ylabel(\"Weekday\", color=\"w\")\n",
    "        plt.xlabel(\"Hour of Day\", color=\"w\")\n",
    "        plt.xticks(color=\"w\")\n",
    "        plt.yticks(color=\"w\")\n",
    "        fig.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        all_figs[\"traffic_heatmap.png\"] = fig\n",
    "    st.markdown(get_csv_download_link(df, \"traffic_heatmap.csv\"), unsafe_allow_html=True)\n",
    "    st.subheader(\"üîó Top URLs\")\n",
    "    top_n = st.slider(\"Top N URLs\", 5, 30, 10, key=\"top_urls_slider\")\n",
    "    df = _run_sql(f\"\"\"\n",
    "        SELECT url, COUNT(*) AS hits\n",
    "        FROM logs\n",
    "        WHERE DATE(time) BETWEEN '{start}' AND '{end}'\n",
    "        GROUP BY url\n",
    "        ORDER BY hits DESC\n",
    "        LIMIT {top_n}\n",
    "    \"\"\")\n",
    "    if not df.empty:\n",
    "        fig, ax = plt.subplots(figsize=(10, 0.6*len(df)+2), facecolor=DARK_BG)\n",
    "        sns.barplot(data=df, y=\"url\", x=\"hits\", palette=\"viridis\", ax=ax, edgecolor=\"black\", linewidth=.5)\n",
    "        for p in ax.patches:\n",
    "            w = p.get_width()\n",
    "            ax.text(w + df[\"hits\"].max()*0.01, p.get_y() + p.get_height()/2, f\"{int(w):,}\", va=\"center\", ha=\"left\", color=\"w\")\n",
    "        ax.set(title=f\"Most Accessed URLs (Top {top_n})\", xlabel=\"Hits (requests)\", ylabel=\"\")\n",
    "        plt.yticks(color=\"w\")\n",
    "        plt.xticks(color=\"w\")\n",
    "        ax.title.set_color(\"w\")\n",
    "        fig.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        all_figs[\"top_urls.png\"] = fig\n",
    "    st.markdown(get_csv_download_link(df, \"top_urls.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Threats ---\n",
    "with tabs[2]:\n",
    "    st.title(\"üö® Threats & Suspicion\")\n",
    "    st.subheader(\"Suspicious IPs by Country\")\n",
    "    days = st.slider(\"Days\", 7, 60, 30, key=\"country_days\")\n",
    "    top_n = st.slider(\"Top N Countries\", 5, 20, 10, key=\"country_topn\")\n",
    "    latest_day = _run_sql(\"SELECT DATE(MAX(time)) AS d FROM logs\").iloc[0, 0]\n",
    "    if latest_day:\n",
    "        start_day = (datetime.fromisoformat(latest_day) - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
    "        df = _run_sql(f\"\"\"\n",
    "            SELECT l.country, COUNT(DISTINCT s.suspiciousIp) AS cnt\n",
    "            FROM   ip_suspicious AS s\n",
    "            JOIN   logs           AS l  ON l.ip = s.suspiciousIp\n",
    "            WHERE  DATE(l.time) BETWEEN '{start_day}' AND '{latest_day}'\n",
    "            GROUP  BY l.country\n",
    "            ORDER  BY cnt DESC\n",
    "            LIMIT  {top_n}\n",
    "        \"\"\")\n",
    "        if not df.empty:\n",
    "            fig_map = px.choropleth(df, locations=\"country\", locationmode=\"country names\",\n",
    "                                    color=\"cnt\", color_continuous_scale=\"Reds\",\n",
    "                                    title=\"Suspicious IPs by Country\",\n",
    "                                    template=\"plotly_dark\")\n",
    "            st.plotly_chart(fig_map, use_container_width=True)\n",
    "            all_figs[\"suspicious_by_country_map.png\"] = fig_map\n",
    "            st.dataframe(df, hide_index=True, use_container_width=True)\n",
    "    st.markdown(get_csv_download_link(df, \"suspicious_by_country.csv\"), unsafe_allow_html=True)\n",
    "    st.subheader(\"Reasons for Suspicion\")\n",
    "    df = _run_sql(f\"\"\"\n",
    "        SELECT reason, COUNT(*) AS cnt\n",
    "        FROM ip_suspicious\n",
    "        WHERE DATE(time) BETWEEN DATE('now', '-{days} day') AND DATE('now')\n",
    "        GROUP BY reason\n",
    "        ORDER BY cnt DESC\n",
    "    \"\"\")\n",
    "    if not df.empty:\n",
    "        fig, ax = plt.subplots(figsize=(10, 0.6*len(df)+2), facecolor=DARK_BG)\n",
    "        sns.barplot(data=df, y=\"reason\", x=\"cnt\", palette=\"Reds\", ax=ax, edgecolor='black', linewidth=0.5)\n",
    "        for p in ax.patches:\n",
    "            width = p.get_width()\n",
    "            ax.text(width + max(df[\"cnt\"]) * 0.01, p.get_y() + p.get_height() / 2, f'{int(width):,}', ha='left', va='center', color=\"w\")\n",
    "        plt.title(f\"Reasons for Suspicious IPs (last {days} days)\", color=\"w\", pad=20)\n",
    "        plt.xlabel(\"Count\", color=\"w\")\n",
    "        plt.ylabel(\"Reason\", color=\"w\")\n",
    "        plt.xticks(color=\"w\")\n",
    "        plt.yticks(color=\"w\")\n",
    "        fig.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        all_figs[\"suspicious_reasons.png\"] = fig\n",
    "    st.markdown(get_csv_download_link(df, \"suspicious_reasons.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Suspicious IPs ---\n",
    "with tabs[3]:\n",
    "    st.title(\"üïµÔ∏è Suspicious IPs\")\n",
    "    search_ip = st.text_input(\"Search IP (partial match allowed)\", key=\"susip_search\")\n",
    "    days = st.slider(\"Days to show\", 1, 30, 7, key=\"susip_days\")\n",
    "    df = _run_sql(f\"\"\"\n",
    "        SELECT suspiciousIp, MAX(time) last_seen, COUNT(*) events, GROUP_CONCAT(DISTINCT reason) reasons\n",
    "        FROM ip_suspicious\n",
    "        WHERE julianday(time) BETWEEN julianday('now', '-{days} day') AND julianday('now')\n",
    "        GROUP BY suspiciousIp\n",
    "        ORDER BY events DESC\n",
    "        LIMIT 100\n",
    "    \"\"\")\n",
    "    if search_ip:\n",
    "        df = df[df['suspiciousIp'].str.contains(search_ip)]\n",
    "    st.dataframe(df, hide_index=True, use_container_width=True)\n",
    "    st.markdown(get_csv_download_link(df, \"suspicious_ips.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Blocked IPs ---\n",
    "with tabs[4]:\n",
    "    st.title(\"‚õî Blocked IPs\")\n",
    "    search_ip = st.text_input(\"Search Blocked IP\", key=\"blockip_search\")\n",
    "    days = st.slider(\"Days to show\", 1, 30, 7, key=\"blockip_days\")\n",
    "    df = _run_sql(f\"\"\"\n",
    "        SELECT ip, detected_at, backend_blocked_at, detection_count, client_blocked_at, client_block_status\n",
    "        FROM blocked_log\n",
    "        WHERE julianday(backend_blocked_at) BETWEEN julianday('now', '-{days} day') AND julianday('now')\n",
    "        ORDER BY detection_count DESC, ip\n",
    "        LIMIT 100\n",
    "    \"\"\")\n",
    "    if search_ip:\n",
    "        df = df[df['ip'].str.contains(search_ip)]\n",
    "    st.dataframe(df, hide_index=True, use_container_width=True)\n",
    "    st.markdown(get_csv_download_link(df, \"blocked_ips.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Geography ---\n",
    "with tabs[5]:\n",
    "    st.title(\"üåç Geography (Latest Day)\")\n",
    "    latest_day = _run_sql(\"SELECT DATE(MAX(time)) AS d FROM logs\").iloc[0, 0]\n",
    "    if latest_day:\n",
    "        df = _run_sql(f\"\"\"\n",
    "            SELECT country, COUNT(*) AS cnt\n",
    "            FROM   logs\n",
    "            WHERE  DATE(time) = '{latest_day}'\n",
    "            GROUP  BY country\n",
    "            ORDER  BY cnt DESC\n",
    "        \"\"\")\n",
    "        st.markdown(\"#### Top 10 Countries by Requests\")\n",
    "        if not df.empty:\n",
    "            top10 = df.head(10)\n",
    "            st.dataframe(top10, hide_index=True, use_container_width=True)\n",
    "            fig_map = px.choropleth(df, locations=\"country\", locationmode=\"country names\",\n",
    "                                    color=\"cnt\", color_continuous_scale=\"Blues\",\n",
    "                                    title=f\"Requests by Country ({latest_day})\",\n",
    "                                    template=\"plotly_dark\")\n",
    "            st.plotly_chart(fig_map, use_container_width=True)\n",
    "            all_figs[\"country_hits_map.png\"] = fig_map\n",
    "            st.markdown(\"#### Drilldown: Select a country for daily trend\")\n",
    "            country_sel = st.selectbox(\"Country\", df[\"country\"], key=\"geo_country_sel\")\n",
    "            df2 = _run_sql(f\"\"\"\n",
    "                SELECT DATE(time) as day, COUNT(*) as cnt\n",
    "                FROM logs\n",
    "                WHERE country = '{country_sel}'\n",
    "                GROUP BY day\n",
    "                ORDER BY day\n",
    "            \"\"\")\n",
    "            if not df2.empty:\n",
    "                fig, ax = plt.subplots(facecolor=DARK_BG)\n",
    "                sns.lineplot(data=df2, x=\"day\", y=\"cnt\", marker=\"o\", ax=ax)\n",
    "                ax.set(title=f\"Daily Requests for {country_sel}\", xlabel=\"Date\", ylabel=\"Hits\")\n",
    "                plt.xticks(rotation=45, ha=\"right\", color=\"w\")\n",
    "                plt.yticks(color=\"w\")\n",
    "                ax.title.set_color(\"w\")\n",
    "                fig.tight_layout()\n",
    "                st.pyplot(fig)\n",
    "                all_figs[f\"country_trend_{country_sel}.png\"] = fig\n",
    "        st.markdown(get_csv_download_link(df, \"country_hits.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Advanced ---\n",
    "with tabs[6]:\n",
    "    st.title(\"üß† Advanced Analytics\")\n",
    "    st.subheader(\"Advanced Log Summary\")\n",
    "    min_date, max_date = _run_sql(\"SELECT MIN(first_time_of_access), MAX(first_time_of_access) FROM advanced_logs\").iloc[0]\n",
    "    if pd.isnull(min_date) or pd.isnull(max_date):\n",
    "        st.info(\"No advanced logs available.\")\n",
    "    else:\n",
    "        date_range = st.date_input(\"Select date range\", value=(pd.to_datetime(min_date), pd.to_datetime(max_date)), key=\"advanced_date_range\")\n",
    "        start, end = date_range if isinstance(date_range, (list, tuple)) else (min_date, max_date)\n",
    "        df = _run_sql(f\"\"\"\n",
    "            SELECT * FROM advanced_logs\n",
    "            WHERE DATE(first_time_of_access) BETWEEN '{start}' AND '{end}'\n",
    "            ORDER BY req_per_min DESC\n",
    "            LIMIT 100\n",
    "        \"\"\")\n",
    "        if df.empty:\n",
    "            st.info(\"No advanced logs in this date range.\")\n",
    "        else:\n",
    "            st.dataframe(df, hide_index=True, use_container_width=True)\n",
    "            st.markdown(get_csv_download_link(df, \"advanced_logs.csv\"), unsafe_allow_html=True)\n",
    "    st.subheader(\"DDoS Incidents\")\n",
    "    df = _run_sql(\"\"\"\n",
    "        SELECT * FROM ddos_multiple_ip\n",
    "        ORDER BY window_end DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    st.dataframe(df, hide_index=True, use_container_width=True)\n",
    "    st.markdown(get_csv_download_link(df, \"ddos_incidents.csv\"), unsafe_allow_html=True)\n",
    "\n",
    "# --- Reports Tab ---\n",
    "def get_latest_platform_pie(static_dir):\n",
    "    pngs = sorted(static_dir.glob(\"platform_pie_day_*.png\"), reverse=True)\n",
    "    return pngs[0] if pngs else None\n",
    "\n",
    "def create_hourly_activity_analysis(df_hourly):\n",
    "    \"\"\"Create comprehensive hourly activity analysis\"\"\"\n",
    "    analysis = []\n",
    "    peak_hours = df_hourly.nlargest(3, 'requests')['hour'].tolist()\n",
    "    low_hours = df_hourly.nsmallest(3, 'requests')['hour'].tolist()\n",
    "    analysis.append(f\"Peak activity hours: {', '.join(map(str, peak_hours))}\")\n",
    "    analysis.append(f\"Low activity hours: {', '.join(map(str, low_hours))}\")\n",
    "    business_hours = df_hourly[(df_hourly['hour'] >= 9) & (df_hourly['hour'] <= 17)]\n",
    "    after_hours = df_hourly[(df_hourly['hour'] < 9) | (df_hourly['hour'] > 17)]\n",
    "    business_total = business_hours['requests'].sum()\n",
    "    after_hours_total = after_hours['requests'].sum()\n",
    "    analysis.append(f\"Business hours (9-17): {business_total:,} requests ({business_total/(business_total+after_hours_total)*100:.1f}%)\")\n",
    "    analysis.append(f\"After hours: {after_hours_total:,} requests ({after_hours_total/(business_total+after_hours_total)*100:.1f}%)\")\n",
    "    return analysis\n",
    "\n",
    "def create_threat_analysis(sus_df, blocked_df):\n",
    "    \"\"\"Create threat landscape analysis\"\"\"\n",
    "    analysis = []\n",
    "    total_suspicious = len(sus_df)\n",
    "    total_blocked = len(blocked_df)\n",
    "    analysis.append(f\"Total suspicious events: {total_suspicious:,}\")\n",
    "    analysis.append(f\"Total blocked IPs: {total_blocked:,}\")\n",
    "    if not sus_df.empty:\n",
    "        top_reasons = sus_df['reason'].value_counts().head(3)\n",
    "        analysis.append(f\"Top threat types: {', '.join(top_reasons.index.tolist())}\")\n",
    "    if total_suspicious > 0:\n",
    "        block_rate = (total_blocked / total_suspicious) * 100\n",
    "        analysis.append(f\"Block rate: {block_rate:.1f}% of suspicious IPs were blocked\")\n",
    "    return analysis\n",
    "\n",
    "def create_geographical_analysis(country_df):\n",
    "    \"\"\"Create geographical threat analysis\"\"\"\n",
    "    analysis = []\n",
    "    if not country_df.empty:\n",
    "        total_countries = len(country_df)\n",
    "        top_country = country_df.iloc[0]\n",
    "        analysis.append(f\"Traffic from {total_countries} countries\")\n",
    "        analysis.append(f\"Top country: {top_country['country']} ({top_country['requests']:,} requests)\")\n",
    "        top_5_total = country_df.head(5)['requests'].sum()\n",
    "        overall_total = country_df['requests'].sum()\n",
    "        concentration = (top_5_total / overall_total) * 100\n",
    "        analysis.append(f\"Top 5 countries represent {concentration:.1f}% of all traffic\")\n",
    "    return analysis\n",
    "\n",
    "def create_advanced_logs_analysis(adv_df):\n",
    "    \"\"\"Create advanced behavioral analysis\"\"\"\n",
    "    analysis = []\n",
    "    if not adv_df.empty:\n",
    "        high_rate = adv_df[adv_df['req_per_min'] > 100]\n",
    "        high_error = adv_df[adv_df['error_rate'] > 0.5]\n",
    "        analysis.append(f\"High-rate IPs (>100 req/min): {len(high_rate)}\")\n",
    "        analysis.append(f\"High error rate IPs (>50%): {len(high_error)}\")\n",
    "        avg_req_rate = adv_df['req_per_min'].mean()\n",
    "        avg_error_rate = adv_df['error_rate'].mean()\n",
    "        analysis.append(f\"Average request rate: {avg_req_rate:.1f} req/min\")\n",
    "        analysis.append(f\"Average error rate: {avg_error_rate:.1%}\")\n",
    "    return analysis\n",
    "\n",
    "def create_ddos_analysis(ddos_df):\n",
    "    \"\"\"Create DDoS incident analysis\"\"\"\n",
    "    analysis = []\n",
    "    if not ddos_df.empty:\n",
    "        total_incidents = len(ddos_df)\n",
    "        max_rps = ddos_df['peak_rps'].max()\n",
    "        max_ips = ddos_df['unique_ips'].max()\n",
    "        analysis.append(f\"Total DDoS incidents: {total_incidents}\")\n",
    "        analysis.append(f\"Peak RPS observed: {max_rps:,}\")\n",
    "        analysis.append(f\"Maximum unique IPs in single incident: {max_ips:,}\")\n",
    "        recent_incidents = ddos_df[ddos_df['window_start'] >= (datetime.now() - timedelta(days=7)).isoformat()]\n",
    "        analysis.append(f\"Recent incidents (last 7 days): {len(recent_incidents)}\")\n",
    "    return analysis\n",
    "\n",
    "def create_enhanced_html_report(report_start, report_end, tables, report_figs, analyses):\n",
    "    \"\"\"Create comprehensive HTML report with all visualizations and analyses\"\"\"\n",
    "    parts = [\n",
    "        \"<html><head><meta charset='utf-8'><title>Blue‚ÄëGuard SIEM - Comprehensive Security Report</title>\"\n",
    "        \"<style>\"\n",
    "        \"body{font-family:'Segoe UI',Tahoma,Geneva,Verdana,sans-serif;background:#0e1117;color:#f0f2f6;line-height:1.6;margin:0;padding:20px;}\"\n",
    "        \"h1{color:#4ba3c7;text-align:center;margin-bottom:30px;font-size:2.5em;}\"\n",
    "        \"h2{color:#4ba3c7;margin-top:40px;margin-bottom:20px;border-bottom:2px solid #4ba3c7;padding-bottom:10px;}\"\n",
    "        \"h3{color:#7dd3fc;margin-top:30px;margin-bottom:15px;}\"\n",
    "        \".analysis{background:#1a1d24;padding:20px;border-radius:10px;margin:20px 0;border-left:4px solid #4ba3c7;}\"\n",
    "        \".analysis h4{color:#4ba3c7;margin-top:0;}\"\n",
    "        \".analysis ul{margin:10px 0;padding-left:20px;}\"\n",
    "        \".analysis li{margin:5px 0;color:#b7e0fa;}\"\n",
    "        \".summary{background:#1a1d24;padding:25px;border-radius:10px;margin:30px 0;border:2px solid #4ba3c7;}\"\n",
    "        \".metric{display:inline-block;margin:10px 20px;padding:15px;background:#2a2e36;border-radius:8px;min-width:150px;text-align:center;}\"\n",
    "        \".metric-value{font-size:2em;font-weight:bold;color:#4ba3c7;}\"\n",
    "        \".metric-label{color:#b7b7b7;font-size:0.9em;}\"\n",
    "        \"table{background:#181c25;color:#f0f2f6;border-radius:8px;margin:20px 0;width:100%;border-collapse:collapse;}\"\n",
    "        \"th,td{padding:12px;text-align:left;border-bottom:1px solid #2a2e36;}\"\n",
    "        \"th{background:#2a2e36;color:#4ba3c7;font-weight:bold;}\"\n",
    "        \"tr:hover{background:#1a1d24;}\"\n",
    "        \".chart-container{margin:20px 0;padding:20px;background:#1a1d24;border-radius:10px;}\"\n",
    "        \".risk-high{color:#ff6b6b;font-weight:bold;}\"\n",
    "        \".risk-medium{color:#ffd93d;font-weight:bold;}\"\n",
    "        \".risk-low{color:#6bcf7f;font-weight:bold;}\"\n",
    "        \".footer{text-align:center;margin-top:50px;padding:20px;color:#7dd3fc;border-top:1px solid #2a2e36;}\"\n",
    "        \"</style></head><body>\"\n",
    "    ]\n",
    "    parts.append(f\"\"\"\n",
    "    <h1>üõ°Ô∏è Blue‚ÄëGuard SIEM - Comprehensive Security Report</h1>\n",
    "    <div class=\"summary\">\n",
    "        <h3>üìä Report Summary</h3>\n",
    "        <p><strong>Analysis Period:</strong> {report_start.strftime('%Y-%m-%d %H:%M')} to {report_end.strftime('%Y-%m-%d %H:%M')}</p>\n",
    "        <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    parts.append('<h2>üìã Executive Summary</h2>')\n",
    "    parts.append('<div class=\"summary\">')\n",
    "    total_logs = len(tables.get(\"Raw Logs Summary\", pd.DataFrame()))\n",
    "    suspicious_ips = len(tables.get(\"Suspicious IPs\", pd.DataFrame()))\n",
    "    blocked_ips = len(tables.get(\"Blocked IPs\", pd.DataFrame()))\n",
    "    ddos_incidents = len(tables.get(\"DDoS Incidents\", pd.DataFrame()))\n",
    "    parts.append(f\"\"\"\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{total_logs:,}</div>\n",
    "        <div class=\"metric-label\">Total Log Events</div>\n",
    "    </div>\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{suspicious_ips:,}</div>\n",
    "        <div class=\"metric-label\">Suspicious IPs</div>\n",
    "    </div>\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{blocked_ips:,}</div>\n",
    "        <div class=\"metric-label\">Blocked IPs</div>\n",
    "    </div>\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{ddos_incidents:,}</div>\n",
    "        <div class=\"metric-label\">DDoS Incidents</div>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    parts.append('</div>')\n",
    "    threat_level = \"LOW\"\n",
    "    threat_color = \"risk-low\"\n",
    "    if ddos_incidents > 5 or suspicious_ips > 100:\n",
    "        threat_level = \"HIGH\"\n",
    "        threat_color = \"risk-high\"\n",
    "    elif ddos_incidents > 1 or suspicious_ips > 20:\n",
    "        threat_level = \"MEDIUM\"\n",
    "        threat_color = \"risk-medium\"\n",
    "    parts.append(f\"\"\"\n",
    "    <div class=\"analysis\">\n",
    "        <h4>üö® Overall Threat Level: <span class=\"{threat_color}\">{threat_level}</span></h4>\n",
    "        <p>Based on DDoS incidents, suspicious IP activity, and blocking patterns observed during the analysis period.</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    sections = [\n",
    "        (\"üïê Traffic Patterns & Activity Analysis\", \"traffic_analysis\"),\n",
    "        (\"üö® Threat Landscape & Security Events\", \"threat_analysis\"),\n",
    "        (\"üåç Geographical Distribution\", \"geo_analysis\"),\n",
    "        (\"üß† Advanced Behavioral Analysis\", \"behavioral_analysis\"),\n",
    "        (\"‚ö° DDoS & Attack Incidents\", \"ddos_analysis\"),\n",
    "        (\"üîÑ System Performance & Metrics\", \"performance_analysis\")\n",
    "    ]\n",
    "    for section_title, section_key in sections:\n",
    "        parts.append(f'<h2>{section_title}</h2>')\n",
    "        if section_key in analyses:\n",
    "            parts.append('<div class=\"analysis\">')\n",
    "            parts.append(f'<h4>Key Insights:</h4>')\n",
    "            parts.append('<ul>')\n",
    "            for insight in analyses[section_key]:\n",
    "                parts.append(f'<li>{insight}</li>')\n",
    "            parts.append('</ul>')\n",
    "            parts.append('</div>')\n",
    "        section_figs = {k: v for k, v in report_figs.items() if section_key in k.lower()}\n",
    "        for fig_name, fig in section_figs.items():\n",
    "            parts.append(f'<div class=\"chart-container\">')\n",
    "            parts.append(f'<h3>{fig_name}</h3>')\n",
    "            if hasattr(fig, \"to_html\"):\n",
    "                parts.append(fig.to_html(full_html=False, include_plotlyjs=\"cdn\", config={\"displayModeBar\": False}))\n",
    "            elif hasattr(fig, \"savefig\"):\n",
    "                buf_png = io.BytesIO()\n",
    "                fig.savefig(buf_png, format=\"png\", facecolor=\"#0e1117\", bbox_inches='tight')\n",
    "                b64 = base64.b64encode(buf_png.getvalue()).decode()\n",
    "                parts.append(f\"<img src='data:image/png;base64,{b64}' style='max-width:100%; height:auto;'/>\")\n",
    "            parts.append('</div>')\n",
    "    parts.append('<h2>üìä Detailed Data Tables</h2>')\n",
    "    for table_name, df in tables.items():\n",
    "        if not df.empty:\n",
    "            parts.append(f'<h3>{table_name}</h3>')\n",
    "            display_df = df.head(20) if len(df) > 20 else df\n",
    "            parts.append(display_df.to_html(index=False, border=0, classes=\"dataframe\", \n",
    "                                          justify=\"center\", na_rep=\"N/A\", table_id=table_name.replace(\" \", \"_\")))\n",
    "            if len(df) > 20:\n",
    "                parts.append(f'<p><em>Showing top 20 of {len(df)} total records</em></p>')\n",
    "        else:\n",
    "            parts.append(f'<h3>{table_name}</h3>')\n",
    "            parts.append('<p><em>No data available for this section</em></p>')\n",
    "    parts.append(f\"\"\"\n",
    "    <div class=\"footer\">\n",
    "        <p>Blue Guard SIEM ¬© 2025 - Comprehensive Security Analysis Report</p>\n",
    "        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Period: {report_start.strftime('%Y-%m-%d')} to {report_end.strftime('%Y-%m-%d')}</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    parts.append(\"</body></html>\")\n",
    "    return \"\\n\".join(parts).encode(\"utf-8\")\n",
    "\n",
    "# --- Reports Tab ---\n",
    "# --- Helper functions for bounds ---\n",
    "def _bounds(table: str, column: str):\n",
    "    q = f\"SELECT MIN({column}) AS min_t, MAX({column}) AS max_t FROM {table}\"\n",
    "    df = _run_sql(q)\n",
    "    if df.empty or df.isnull().any(axis=None):\n",
    "        return None, None\n",
    "    return pd.to_datetime(df.min_t[0]), pd.to_datetime(df.max_t[0])\n",
    "\n",
    "LOG_MIN, LOG_MAX = _bounds(\"logs\", \"time\")\n",
    "SUS_MIN, SUS_MAX = _bounds(\"ip_suspicious\", \"time\")\n",
    "BLK_MIN, BLK_MAX = _bounds(\"blocked_log\", \"backend_blocked_at\")\n",
    "ADV_MIN, ADV_MAX = _bounds(\"advanced_logs\", \"first_time_of_access\")\n",
    "DDOS_MIN, DDOS_MAX = _bounds(\"ddos_multiple_ip\", \"window_start\")\n",
    "\n",
    "# Global span across all tables\n",
    "GLOBAL_MIN = min(ts for ts in (LOG_MIN, SUS_MIN, BLK_MIN, ADV_MIN, DDOS_MIN) if ts is not None)\n",
    "GLOBAL_MAX = max(ts for ts in (LOG_MAX, SUS_MAX, BLK_MAX, ADV_MAX, DDOS_MAX) if ts is not None)\n",
    "\n",
    "def get_latest_platform_pie(static_dir):\n",
    "    pngs = sorted(static_dir.glob(\"platform_pie_day_*.png\"), reverse=True)\n",
    "    return pngs[0] if pngs else None\n",
    "\n",
    "def create_hourly_activity_analysis(df_hourly):\n",
    "    df_hourly['hour'] = df_hourly['hour'].astype(int)\n",
    "\n",
    "    \"\"\"Create comprehensive hourly activity analysis\"\"\"\n",
    "    analysis = []\n",
    "    peak_hours = df_hourly.nlargest(3, 'requests')['hour'].tolist()\n",
    "    low_hours = df_hourly.nsmallest(3, 'requests')['hour'].tolist()\n",
    "    analysis.append(f\"Peak activity hours: {', '.join(map(str, peak_hours))}\")\n",
    "    analysis.append(f\"Low activity hours: {', '.join(map(str, low_hours))}\")\n",
    "    business_hours = df_hourly[(df_hourly['hour'] >= 9) & (df_hourly['hour'] <= 17)]\n",
    "    after_hours = df_hourly[(df_hourly['hour'] < 9) | (df_hourly['hour'] > 17)]\n",
    "    business_total = business_hours['requests'].sum()\n",
    "    after_hours_total = after_hours['requests'].sum()\n",
    "    analysis.append(f\"Business hours (9-17): {business_total:,} requests ({business_total/(business_total+after_hours_total)*100:.1f}%)\")\n",
    "    analysis.append(f\"After hours: {after_hours_total:,} requests ({after_hours_total/(business_total+after_hours_total)*100:.1f}%)\")\n",
    "    return analysis\n",
    "\n",
    "def create_threat_analysis(sus_df, blocked_df):\n",
    "    \"\"\"Create threat landscape analysis\"\"\"\n",
    "    analysis = []\n",
    "    total_suspicious = len(sus_df)\n",
    "    total_blocked = len(blocked_df)\n",
    "    analysis.append(f\"Total suspicious events: {total_suspicious:,}\")\n",
    "    analysis.append(f\"Total blocked IPs: {total_blocked:,}\")\n",
    "    if not sus_df.empty:\n",
    "        top_reasons = sus_df['reason'].value_counts().head(3)\n",
    "        analysis.append(f\"Top threat types: {', '.join(top_reasons.index.tolist())}\")\n",
    "    if total_suspicious > 0:\n",
    "        block_rate = (total_blocked / total_suspicious) * 100\n",
    "        analysis.append(f\"Block rate: {block_rate:.1f}% of suspicious IPs were blocked\")\n",
    "    return analysis\n",
    "\n",
    "def create_geographical_analysis(country_df):\n",
    "    \"\"\"Create geographical threat analysis\"\"\"\n",
    "    analysis = []\n",
    "    if not country_df.empty:\n",
    "        total_countries = len(country_df)\n",
    "        top_country = country_df.iloc[0]\n",
    "        analysis.append(f\"Traffic from {total_countries} countries\")\n",
    "        analysis.append(f\"Top country: {top_country['country']} ({top_country['requests']:,} requests)\")\n",
    "        top_5_total = country_df.head(5)['requests'].sum()\n",
    "        overall_total = country_df['requests'].sum()\n",
    "        concentration = (top_5_total / overall_total) * 100\n",
    "        analysis.append(f\"Top 5 countries represent {concentration:.1f}% of all traffic\")\n",
    "    return analysis\n",
    "\n",
    "def create_advanced_logs_analysis(adv_df):\n",
    "    \"\"\"Create advanced behavioral analysis\"\"\"\n",
    "    analysis = []\n",
    "    if not adv_df.empty:\n",
    "        high_rate = adv_df[adv_df['req_per_min'] > 100]\n",
    "        high_error = adv_df[adv_df['error_rate'] > 0.5]\n",
    "        analysis.append(f\"High-rate IPs (>100 req/min): {len(high_rate)}\")\n",
    "        analysis.append(f\"High error rate IPs (>50%): {len(high_error)}\")\n",
    "        avg_req_rate = adv_df['req_per_min'].mean()\n",
    "        avg_error_rate = adv_df['error_rate'].mean()\n",
    "        analysis.append(f\"Average request rate: {avg_req_rate:.1f} req/min\")\n",
    "        analysis.append(f\"Average error rate: {avg_error_rate:.1%}\")\n",
    "    return analysis\n",
    "\n",
    "def create_ddos_analysis(ddos_df):\n",
    "    \"\"\"Create DDoS incident analysis\"\"\"\n",
    "    analysis = []\n",
    "    if not ddos_df.empty:\n",
    "        total_incidents = len(ddos_df)\n",
    "        max_rps = ddos_df['peak_rps'].max()\n",
    "        max_ips = ddos_df['unique_ips'].max()\n",
    "        analysis.append(f\"Total DDoS incidents: {total_incidents}\")\n",
    "        analysis.append(f\"Peak RPS observed: {max_rps:,}\")\n",
    "        analysis.append(f\"Maximum unique IPs in single incident: {max_ips:,}\")\n",
    "        recent_incidents = ddos_df[ddos_df['window_start'] >= (datetime.now() - timedelta(days=7)).isoformat()]\n",
    "        analysis.append(f\"Recent incidents (last 7 days): {len(recent_incidents)}\")\n",
    "    return analysis\n",
    "\n",
    "def create_enhanced_html_report(report_start, report_end, tables, report_figs, analyses):\n",
    "    \"\"\"Create comprehensive HTML report with all visualizations and analyses\"\"\"\n",
    "    parts = [\n",
    "        \"<html><head><meta charset='utf-8'><title>Blue‚ÄëGuard SIEM - Comprehensive Security Report</title>\"\n",
    "        \"<style>\"\n",
    "        \"body{font-family:'Segoe UI',Tahoma,Geneva,Verdana,sans-serif;background:#0e1117;color:#f0f2f6;line-height:1.6;margin:0;padding:20px;}\"\n",
    "        \"h1{color:#4ba3c7;text-align:center;margin-bottom:30px;font-size:2.5em;}\"\n",
    "        \"h2{color:#4ba3c7;margin-top:40px;margin-bottom:20px;border-bottom:2px solid #4ba3c7;padding-bottom:10px;}\"\n",
    "        \"h3{color:#7dd3fc;margin-top:30px;margin-bottom:15px;}\"\n",
    "        \".analysis{background:#1a1d24;padding:20px;border-radius:10px;margin:20px 0;border-left:4px solid #4ba3c7;}\"\n",
    "        \".analysis h4{color:#4ba3c7;margin-top:0;}\"\n",
    "        \".analysis ul{margin:10px 0;padding-left:20px;}\"\n",
    "        \".analysis li{margin:5px 0;color:#b7e0fa;}\"\n",
    "        \".summary{background:#1a1d24;padding:25px;border-radius:10px;margin:30px 0;border:2px solid #4ba3c7;}\"\n",
    "        \".metric{display:inline-block;margin:10px 20px;padding:15px;background:#2a2e36;border-radius:8px;min-width:150px;text-align:center;}\"\n",
    "        \".metric-value{font-size:2em;font-weight:bold;color:#4ba3c7;}\"\n",
    "        \".metric-label{color:#b7b7b7;font-size:0.9em;}\"\n",
    "        \"table{background:#181c25;color:#f0f2f6;border-radius:8px;margin:20px 0;width:100%;border-collapse:collapse;}\"\n",
    "        \"th,td{padding:12px;text-align:left;border-bottom:1px solid #2a2e36;}\"\n",
    "        \"th{background:#2a2e36;color:#4ba3c7;font-weight:bold;}\"\n",
    "        \"tr:hover{background:#1a1d24;}\"\n",
    "        \".chart-container{margin:20px 0;padding:20px;background:#1a1d24;border-radius:10px;}\"\n",
    "        \".risk-high{color:#ff6b6b;font-weight:bold;}\"\n",
    "        \".risk-medium{color:#ffd93d;font-weight:bold;}\"\n",
    "        \".risk-low{color:#6bcf7f;font-weight:bold;}\"\n",
    "        \".footer{text-align:center;margin-top:50px;padding:20px;color:#7dd3fc;border-top:1px solid #2a2e36;}\"\n",
    "        \"</style></head><body>\"\n",
    "    ]\n",
    "    parts.append(f\"\"\"\n",
    "    <h1>üõ°Ô∏è Blue‚ÄëGuard SIEM - Comprehensive Security Report</h1>\n",
    "    <div class=\"summary\">\n",
    "        <h3>üìä Report Summary</h3>\n",
    "        <p><strong>Analysis Period:</strong> {report_start.strftime('%Y-%m-%d %H:%M')} to {report_end.strftime('%Y-%m-%d %H:%M')}</p>\n",
    "        <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    parts.append('<h2>üìã Executive Summary</h2>')\n",
    "    parts.append('<div class=\"summary\">')\n",
    "    total_logs = len(tables.get(\"Raw Logs Summary\", pd.DataFrame()))\n",
    "    suspicious_ips = len(tables.get(\"Suspicious IPs\", pd.DataFrame()))\n",
    "    blocked_ips = len(tables.get(\"Blocked IPs\", pd.DataFrame()))\n",
    "    ddos_incidents = len(tables.get(\"DDoS Incidents\", pd.DataFrame()))\n",
    "    parts.append(f\"\"\"\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{total_logs:,}</div>\n",
    "        <div class=\"metric-label\">Total Log Events</div>\n",
    "    </div>\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{suspicious_ips:,}</div>\n",
    "        <div class=\"metric-label\">Suspicious IPs</div>\n",
    "    </div>\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{blocked_ips:,}</div>\n",
    "        <div class=\"metric-label\">Blocked IPs</div>\n",
    "    </div>\n",
    "    <div class=\"metric\">\n",
    "        <div class=\"metric-value\">{ddos_incidents:,}</div>\n",
    "        <div class=\"metric-label\">DDoS Incidents</div>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    parts.append('</div>')\n",
    "    threat_level = \"LOW\"\n",
    "    threat_color = \"risk-low\"\n",
    "    if ddos_incidents > 5 or suspicious_ips > 100:\n",
    "        threat_level = \"HIGH\"\n",
    "        threat_color = \"risk-high\"\n",
    "    elif ddos_incidents > 1 or suspicious_ips > 20:\n",
    "        threat_level = \"MEDIUM\"\n",
    "        threat_color = \"risk-medium\"\n",
    "    parts.append(f\"\"\"\n",
    "    <div class=\"analysis\">\n",
    "        <h4>üö® Overall Threat Level: <span class=\"{threat_color}\">{threat_level}</span></h4>\n",
    "        <p>Based on DDoS incidents, suspicious IP activity, and blocking patterns observed during the analysis period.</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    sections = [\n",
    "        (\"üïê Traffic Patterns & Activity Analysis\", \"traffic_analysis\"),\n",
    "        (\"üö® Threat Landscape & Security Events\", \"threat_analysis\"),\n",
    "        (\"üåç Geographical Distribution\", \"geo_analysis\"),\n",
    "        (\"üß† Advanced Behavioral Analysis\", \"behavioral_analysis\"),\n",
    "        (\"‚ö° DDoS & Attack Incidents\", \"ddos_analysis\"),\n",
    "        (\"üîÑ System Performance & Metrics\", \"performance_analysis\")\n",
    "    ]\n",
    "    for section_title, section_key in sections:\n",
    "        parts.append(f'<h2>{section_title}</h2>')\n",
    "        if section_key in analyses:\n",
    "            parts.append('<div class=\"analysis\">')\n",
    "            parts.append(f'<h4>Key Insights:</h4>')\n",
    "            parts.append('<ul>')\n",
    "            for insight in analyses[section_key]:\n",
    "                parts.append(f'<li>{insight}</li>')\n",
    "            parts.append('</ul>')\n",
    "            parts.append('</div>')\n",
    "        section_figs = {k: v for k, v in report_figs.items() if section_key in k.lower()}\n",
    "        for fig_name, fig in section_figs.items():\n",
    "            parts.append(f'<div class=\"chart-container\">')\n",
    "            parts.append(f'<h3>{fig_name}</h3>')\n",
    "            if hasattr(fig, \"to_html\"):\n",
    "                parts.append(fig.to_html(full_html=False, include_plotlyjs=\"cdn\", config={\"displayModeBar\": False}))\n",
    "            elif hasattr(fig, \"savefig\"):\n",
    "                buf_png = io.BytesIO()\n",
    "                fig.savefig(buf_png, format=\"png\", facecolor=\"#0e1117\", bbox_inches='tight')\n",
    "                b64 = base64.b64encode(buf_png.getvalue()).decode()\n",
    "                parts.append(f\"<img src='data:image/png;base64,{b64}' style='max-width:100%; height:auto;'/>\")\n",
    "            parts.append('</div>')\n",
    "    parts.append('<h2>üìä Detailed Data Tables</h2>')\n",
    "    for table_name, df in tables.items():\n",
    "        if not df.empty:\n",
    "            parts.append(f'<h3>{table_name}</h3>')\n",
    "            display_df = df.head(20) if len(df) > 20 else df\n",
    "            parts.append(display_df.to_html(index=False, border=0, classes=\"dataframe\", \n",
    "                                          justify=\"center\", na_rep=\"N/A\", table_id=table_name.replace(\" \", \"_\")))\n",
    "            if len(df) > 20:\n",
    "                parts.append(f'<p><em>Showing top 20 of {len(df)} total records</em></p>')\n",
    "        else:\n",
    "            parts.append(f'<h3>{table_name}</h3>')\n",
    "            parts.append('<p><em>No data available for this section</em></p>')\n",
    "    parts.append(f\"\"\"\n",
    "    <div class=\"footer\">\n",
    "        <p>Blue Guard SIEM ¬© 2025 - Comprehensive Security Analysis Report</p>\n",
    "        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Period: {report_start.strftime('%Y-%m-%d')} to {report_end.strftime('%Y-%m-%d')}</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    parts.append(\"</body></html>\")\n",
    "    return \"\\n\".join(parts).encode(\"utf-8\")\n",
    "\n",
    "# --- Reports Tab ---\n",
    "def render_reports_tab():\n",
    "    st.title(\"üìÑ Comprehensive Security Analysis Report\")\n",
    "    st.caption(f\"Full data span: {GLOBAL_MIN.date()} to {GLOBAL_MAX.date()}\")\n",
    "\n",
    "    # Date range selector\n",
    "    report_range = st.date_input(\n",
    "        \"Select analysis period for comprehensive report\",\n",
    "        value=(GLOBAL_MIN.date(), GLOBAL_MAX.date()),\n",
    "        min_value=GLOBAL_MIN.date(),\n",
    "        max_value=GLOBAL_MAX.date(),\n",
    "        key=\"comprehensive_report_range\",\n",
    "    )\n",
    "\n",
    "    report_start = datetime.combine(report_range[0], datetime.min.time())\n",
    "    report_end = datetime.combine(report_range[1], datetime.max.time())\n",
    "\n",
    "    # Report generation\n",
    "    if st.button(\"üîÑ Generate Comprehensive Security Report\", use_container_width=True):\n",
    "        with st.spinner(\"üîç Analyzing security data and generating comprehensive report...\"):\n",
    "            tables = {}\n",
    "\n",
    "            # Raw logs summary\n",
    "            tables[\"Raw Logs Summary\"] = _run_sql(\"\"\"\n",
    "                SELECT country, method, status, COUNT(*) as requests,\n",
    "                       AVG(size) as avg_size, MIN(time) as first_seen, MAX(time) as last_seen\n",
    "                FROM logs \n",
    "                WHERE time BETWEEN ? AND ?\n",
    "                GROUP BY country, method, status\n",
    "                ORDER BY requests DESC\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # Suspicious IPs\n",
    "            tables[\"Suspicious IPs\"] = _run_sql(\"\"\"\n",
    "                SELECT suspiciousIp, time, reason, detection_count\n",
    "                FROM ip_suspicious\n",
    "                WHERE time BETWEEN ? AND ?\n",
    "                ORDER BY detection_count DESC, time DESC\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # Blocked IPs\n",
    "            tables[\"Blocked IPs\"] = _run_sql(\"\"\"\n",
    "                SELECT ip, detected_at, backend_blocked_at, detection_count,\n",
    "                       client_blocked_at, client_block_status\n",
    "                FROM blocked_log\n",
    "                WHERE backend_blocked_at BETWEEN ? AND ?\n",
    "                ORDER BY detection_count DESC\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # Advanced logs\n",
    "            tables[\"Advanced Behavioral Analysis\"] = _run_sql(\"\"\"\n",
    "                SELECT ip, req_per_min, unique_urls, error_rate, avg_req_size_bytes,\n",
    "                       method_ratio_post_by_get, first_time_of_access\n",
    "                FROM advanced_logs\n",
    "                WHERE first_time_of_access BETWEEN ? AND ?\n",
    "                ORDER BY req_per_min DESC\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # DDoS incidents\n",
    "            tables[\"DDoS Incidents\"] = _run_sql(\"\"\"\n",
    "                SELECT window_start, window_end, duration_s, total_hits,\n",
    "                       unique_ips, peak_rps, inserted_at\n",
    "                FROM ddos_multiple_ip\n",
    "                WHERE window_start BETWEEN ? AND ?\n",
    "                ORDER BY peak_rps DESC\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # Hourly analysis\n",
    "            tables[\"Hourly Activity Pattern\"] = _run_sql(\"\"\"\n",
    "                SELECT strftime('%H', time) as hour, COUNT(*) as requests,\n",
    "                       COUNT(DISTINCT ip) as unique_ips,\n",
    "                       AVG(size) as avg_size\n",
    "                FROM logs\n",
    "                WHERE time BETWEEN ? AND ?\n",
    "                GROUP BY hour\n",
    "                ORDER BY hour\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # Country analysis\n",
    "            tables[\"Geographical Distribution\"] = _run_sql(\"\"\"\n",
    "                SELECT country, COUNT(*) as requests,\n",
    "                       COUNT(DISTINCT ip) as unique_ips,\n",
    "                       AVG(size) as avg_request_size\n",
    "                FROM logs\n",
    "                WHERE time BETWEEN ? AND ?\n",
    "                GROUP BY country\n",
    "                ORDER BY requests DESC\n",
    "            \"\"\", params=[report_start, report_end])\n",
    "\n",
    "            # IP categorization from ip_eachHour_category\n",
    "            tables[\"IP Behavioral Categories\"] = _run_sql(\"\"\"\n",
    "                SELECT category, COUNT(DISTINCT ip) as unique_ips,\n",
    "                       AVG(hour) as avg_active_hour\n",
    "                FROM ip_eachHour_category\n",
    "                GROUP BY category\n",
    "                ORDER BY unique_ips DESC\n",
    "            \"\"\")\n",
    "\n",
    "            # Generate visualizations\n",
    "            report_figs = {}\n",
    "            analyses = {}\n",
    "\n",
    "            # Example color palettes\n",
    "            BAR_COLORS = px.colors.qualitative.Bold\n",
    "            PIE_COLORS = px.colors.qualitative.Pastel\n",
    "            CHORO_COLORS = px.colors.sequential.Plasma\n",
    "            SCATTER_COLORS = px.colors.sequential.Viridis\n",
    "\n",
    "            # 1. Traffic Analysis (Bar)\n",
    "            hourly_df = tables[\"Hourly Activity Pattern\"]\n",
    "            if not hourly_df.empty:\n",
    "                fig_hourly = px.bar(\n",
    "                    hourly_df, x='hour', y='requests',\n",
    "                    title='Hourly Request Distribution',\n",
    "                    labels={'hour': 'Hour of Day', 'requests': 'Number of Requests'},\n",
    "                    color='requests',\n",
    "                    color_continuous_scale='Plasma'\n",
    "                )\n",
    "                fig_hourly.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    xaxis=dict(showgrid=False, color='#f0f2f6'),\n",
    "                    yaxis=dict(showgrid=True, gridcolor='#2a2e36', color='#f0f2f6')\n",
    "                )\n",
    "                report_figs[\"traffic_analysis_hourly\"] = fig_hourly\n",
    "\n",
    "            # 2. Threat Analysis (Pie and Line)\n",
    "            sus_df = tables[\"Suspicious IPs\"]\n",
    "            blocked_df = tables[\"Blocked IPs\"]\n",
    "            if not sus_df.empty:\n",
    "                sus_timeline = sus_df.copy()\n",
    "                sus_timeline['date'] = pd.to_datetime(sus_timeline['time']).dt.date\n",
    "                daily_threats = sus_timeline.groupby('date').size().reset_index(name='threats')\n",
    "                # Line chart for timeline\n",
    "                fig_threats = px.line(\n",
    "                    daily_threats, x='date', y='threats',\n",
    "                    title='Daily Threat Detection Timeline',\n",
    "                    labels={'date': 'Date', 'threats': 'Suspicious Events'},\n",
    "                    markers=True\n",
    "                )\n",
    "                fig_threats.update_traces(line_color='#FFD93D')\n",
    "                fig_threats.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    xaxis=dict(showgrid=False, color='#f0f2f6'),\n",
    "                    yaxis=dict(showgrid=True, gridcolor='#2a2e36', color='#f0f2f6')\n",
    "                    )\n",
    "                report_figs[\"threat_analysis_timeline\"] = fig_threats\n",
    "\n",
    "                # Pie chart for threat reasons\n",
    "                report_figs[\"threat_analysis_timeline\"] = fig_threats\n",
    "                threat_reasons = sus_df['reason'].value_counts().reset_index()\n",
    "                threat_reasons.columns = ['reason', 'count']\n",
    "                fig_reasons = px.pie(\n",
    "                    threat_reasons, values='count', names='reason',\n",
    "                    title='Distribution of Threat Types',\n",
    "                    color_discrete_sequence=PIE_COLORS\n",
    "                )\n",
    "                fig_reasons.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    legend_font_color='#f0f2f6'\n",
    "                )\n",
    "                report_figs[\"threat_analysis_reasons\"] = fig_reasons\n",
    "\n",
    "            # 3. Geographical Analysis (Choropleth and Bar)\n",
    "            geo_df = tables[\"Geographical Distribution\"]\n",
    "            if not geo_df.empty:\n",
    "                top_countries = geo_df.head(10)\n",
    "                fig_geo = px.choropleth(\n",
    "                    geo_df, locations='country', locationmode='country names',\n",
    "                    color='requests', hover_data=['unique_ips'],\n",
    "                    title='Global Request Distribution',\n",
    "                    color_continuous_scale=CHORO_COLORS\n",
    "                )\n",
    "                fig_geo.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7'\n",
    "                )\n",
    "                report_figs[\"geo_analysis_map\"] = fig_geo\n",
    "\n",
    "                fig_countries = px.bar(\n",
    "                    top_countries, x='country', y='requests',\n",
    "                    title='Top 10 Countries by Request Volume',\n",
    "                    color='requests',\n",
    "                    color_continuous_scale='Turbo'\n",
    "                )\n",
    "                fig_countries.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    xaxis=dict(showgrid=False, color='#f0f2f6'),\n",
    "                    yaxis=dict(showgrid=True, gridcolor='#2a2e36', color='#f0f2f6')\n",
    "                )\n",
    "                report_figs[\"geo_analysis_top_countries\"] = fig_countries\n",
    "\n",
    "            # 4. Advanced Behavioral Analysis (Scatter and Histogram)\n",
    "            adv_df = tables[\"Advanced Behavioral Analysis\"]\n",
    "            if not adv_df.empty:\n",
    "                fig_scatter = px.scatter(\n",
    "                    adv_df, x='req_per_min', y='error_rate',\n",
    "                    size='unique_urls', hover_data=['ip'],\n",
    "                    title='IP Behavior: Request Rate vs Error Rate',\n",
    "                    color='error_rate',\n",
    "                    color_continuous_scale='Turbo'\n",
    "                )\n",
    "                fig_scatter.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    xaxis=dict(color='#f0f2f6'),\n",
    "                    yaxis=dict(color='#f0f2f6')\n",
    "                )\n",
    "                report_figs[\"behavioral_analysis_scatter\"] = fig_scatter\n",
    "\n",
    "                fig_methods = px.histogram(\n",
    "                    adv_df, x='method_ratio_post_by_get', nbins=20,\n",
    "                    title='Distribution of POST/GET Ratios',\n",
    "                    color_discrete_sequence=BAR_COLORS\n",
    "                )\n",
    "                fig_methods.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    xaxis=dict(color='#f0f2f6'),\n",
    "                    yaxis=dict(color='#f0f2f6')\n",
    "                )\n",
    "                report_figs[\"behavioral_analysis_methods\"] = fig_methods\n",
    "\n",
    "            # 5. DDoS Analysis (Scatter)\n",
    "            ddos_df = tables[\"DDoS Incidents\"]\n",
    "            if not ddos_df.empty:\n",
    "                fig_ddos = px.scatter(\n",
    "                    ddos_timeline, x='window_start', y='peak_rps',\n",
    "                    size='unique_ips', hover_data=['total_hits'],\n",
    "                    title='DDoS Incidents: Peak RPS vs Time',\n",
    "                    color='peak_rps',\n",
    "                    color_continuous_scale='Turbo'\n",
    "                )\n",
    "                fig_ddos.update_layout(\n",
    "                    template='plotly_dark',\n",
    "                    plot_bgcolor='#0e1117',\n",
    "                    paper_bgcolor='#0e1117',\n",
    "                    font_color='#f0f2f6',\n",
    "                    title_font_color='#4ba3c7',\n",
    "                    xaxis=dict(color='#f0f2f6'),\n",
    "                    yaxis=dict(color='#f0f2f6')\n",
    "                )\n",
    "                report_figs[\"ddos_analysis_timeline\"] = fig_ddos\n",
    "\n",
    "\n",
    "            # 6. Performance metrics\n",
    "            total_requests = sum(df['requests'].sum() if 'requests' in df.columns \n",
    "                               else len(df) for df in tables.values())\n",
    "            analyses[\"performance_analysis\"] = [\n",
    "                f\"Total processed events: {total_requests:,}\",\n",
    "                f\"Analysis period: {(report_end - report_start).days} days\",\n",
    "                f\"Average daily events: {total_requests / max(1, (report_end - report_start).days):,.0f}\",\n",
    "                f\"Peak hourly rate: {hourly_df['requests'].max() if not hourly_df.empty else 0:,} requests/hour\"\n",
    "            ]\n",
    "\n",
    "            # Generate HTML report\n",
    "            html_report = create_enhanced_html_report(\n",
    "                report_start, report_end, tables, report_figs, analyses\n",
    "            )\n",
    "\n",
    "            # Save report\n",
    "            filename = f\"BlueGuard_Comprehensive_Report_{report_start.strftime('%Y%m%d')}_{report_end.strftime('%Y%m%d')}.html\"\n",
    "            filepath = REPORTS_DIR / filename\n",
    "\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(html_report)\n",
    "\n",
    "            st.success(f\"‚úÖ Comprehensive report generated successfully!\")\n",
    "\n",
    "            \n",
    "            # --- INLINE PREVIEW OF THE JUST‚ÄëCREATED REPORT -------------\n",
    "            with st.expander(\"üëÅÔ∏è Preview the new report\", expanded=False):\n",
    "                st.components.v1.html(\n",
    "                    html_report.decode(\"utf-8\"),\n",
    "                    height=600,\n",
    "                    scrolling=True\n",
    "                )\n",
    "            # Display key insights \n",
    "            st.subheader(\"üîç Key Security Insights\")\n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            with col1:\n",
    "                st.metric(\"Total Events\", f\"{total_requests:,}\")\n",
    "            with col2:\n",
    "                st.metric(\"Suspicious IPs\", f\"{len(tables['Suspicious IPs']):,}\")\n",
    "            with col3:\n",
    "                st.metric(\"Blocked IPs\", f\"{len(tables['Blocked IPs']):,}\")\n",
    "            with col4:\n",
    "                st.metric(\"DDoS Incidents\", f\"{len(tables['DDoS Incidents']):,}\")\n",
    "\n",
    "            # Provide download link for the new report\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                bytes_data = f.read()\n",
    "                b64 = base64.b64encode(bytes_data).decode()\n",
    "                href = f'<a href=\"data:file/html;base64,{b64}\" download=\"{filename}\">‚¨áÔ∏è Download This Report</a>'\n",
    "                st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "    # --- Section: View & Download Previous Reports ---\n",
    "    st.header(\"üìÇ View & Download Previously Generated Reports\")\n",
    "    reports = sorted(REPORTS_DIR.glob(\"*.html\"), reverse=True)\n",
    "    if not reports:\n",
    "        st.info(\"No previously generated reports found.\")\n",
    "    else:\n",
    "        report_names = [r.name for r in reports]\n",
    "        selected_report = st.selectbox(\"Select a report to view or download\", report_names)\n",
    "        # if selected_report:\n",
    "        #     report_path = REPORTS_DIR / selected_report\n",
    "        #     with open(report_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        #         report_html = f.read()\n",
    "        #     st.markdown(\n",
    "        #         f\"<iframe srcdoc='{report_html}' style='width:100%; height:600px; border:none;'></iframe>\",\n",
    "        #         unsafe_allow_html=True,\n",
    "        #     )\n",
    "        if selected_report:\n",
    "            report_path = REPORTS_DIR / selected_report\n",
    "\n",
    "            # read HTML\n",
    "            with open(report_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                report_html = f.read()\n",
    "\n",
    "            # --- INLINE VIEW OF SELECTED REPORT -----------------------\n",
    "            st.components.v1.html(\n",
    "                report_html,          # raw HTML\n",
    "                height=600,\n",
    "                scrolling=True\n",
    "            )\n",
    "\n",
    "            # --- DOWNLOAD LINK ----------------------------------------\n",
    "            with open(report_path, \"rb\") as f:\n",
    "                b64 = base64.b64encode(f.read()).decode()\n",
    "            st.markdown(\n",
    "                f'<a href=\"data:file/html;base64,{b64}\" download=\"{selected_report}\">‚¨áÔ∏è¬†Download‚ÄØReport</a>',\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "\n",
    "            with open(report_path, \"rb\") as f:\n",
    "                bytes_data = f.read()\n",
    "                b64 = base64.b64encode(bytes_data).decode()\n",
    "                href = f'<a href=\"data:file/html;base64,{b64}\" download=\"{selected_report}\">‚¨áÔ∏è Download Selected Report</a>'\n",
    "                st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "# To use in your Streamlit app, call render_reports_tab() in your main page logic.\n",
    "\n",
    "render_reports_tab()\n",
    "# --- System ---\n",
    "with tabs[8]:\n",
    "    st.title(\"‚öôÔ∏è System Info\")\n",
    "    st.write(f\"**DB file:** `{DB_PATH}` ¬†‚Ä¢ {os.path.getsize(DB_PATH)/(1024**2):.2f}¬†MB\")\n",
    "    st.write(f\"**Log‚Äëtime span:** {LOG_MIN} ‚Üí {LOG_MAX}\")\n",
    "    st.write(f\"**Ingest‚Äëtime span:** {ING_MIN} ‚Üí {ING_MAX}\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"<div style='text-align:center;color:#a1a9b7;font-size:12px;'>\"\n",
    "    \"Blue‚ÄØGuard¬†SIEM¬†¬©¬†2025 ‚Äì Unified Multi-Tab Dashboard</div>\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
